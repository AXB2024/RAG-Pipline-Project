{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AXB2024/RAG-Pipline-Project/blob/main/RAG_PIPELINE_FINAL_PROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssq-KviYDit1"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index llama-index-embeddings-huggingface transformers accelerate sentence-transformers faiss-cpu llama-cpp-python unstructured PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAI2doiCDzbj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "import time\n",
        "import faiss\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from llama_cpp import Llama\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf -O {\"/content/mistral-7b-instruct-v0.2.Q4_K_M.gguf\"}"
      ],
      "metadata": {
        "id": "WCUiOLhiJGwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "048FVplmD0gR"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Mount / Create Document Folder\n",
        "!mkdir documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWZOf9phD362"
      },
      "outputs": [],
      "source": [
        "\"\"\"from google.colab import files\n",
        "uploaded = files.upload()\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6db2tNtD5Zz"
      },
      "outputs": [],
      "source": [
        "\"\"\"import shutil\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    shutil.move(filename, f'documents/{filename}')\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lU-3JJUWD7Um"
      },
      "outputs": [],
      "source": [
        "# STEP 2: Extract Text from PDFs\n",
        "def extract_text_from_pdfs(folder=\"/content/documents\"):\n",
        "    docs = {}\n",
        "    for fname in os.listdir(folder):\n",
        "        if fname.endswith(\".pdf\"):\n",
        "            with fitz.open(os.path.join(folder, fname)) as doc:\n",
        "                full_text = \"\"\n",
        "                for page in doc:\n",
        "                    full_text += page.get_text()\n",
        "                docs[fname] = full_text\n",
        "    return docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDt5zSXIF_QC"
      },
      "outputs": [],
      "source": [
        "# STEP 3: RAG Components\n",
        "queries = {\n",
        "    \"appraisal.pdf\": \"What is the estimated home value?\",\n",
        "    \"sample_bank_statement.pdf\": \"How much was the last transaction?\",\n",
        "    \"payslip_sample_image.pdf\": \"What is the total net salary for this month?\",\n",
        "    \"sample_contract.pdf\" : \"What are the penalties for late payments?\",\n",
        "    \"LenderFeesWorksheetNew.pdf\" : \"What is the total estimated monthly payment?\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CuhS1O7k7L9"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.schema import Document\n",
        "\n",
        "def embed_documents(docs, embedder, chunk_size=300, chunk_overlap=30, use_semantic=True):\n",
        "    if use_semantic:\n",
        "        print(f\"\\nüîß Semantic Chunking | Size: {chunk_size} | Overlap: {chunk_overlap}\")\n",
        "\n",
        "        # Set up semantic chunking\n",
        "        embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "        splitter = SemanticSplitterNodeParser(\n",
        "            embed_model=embed_model,\n",
        "            chunk_size=chunk_size,\n",
        "            chunk_overlap=chunk_overlap,\n",
        "        )\n",
        "\n",
        "        raw_documents = [Document(text=content, metadata={\"name\": name}) for name, content in docs.items()]\n",
        "        nodes = splitter.get_nodes_from_documents(raw_documents)\n",
        "\n",
        "        passages = [node.text for node in nodes]\n",
        "        doc_map = [node.metadata[\"name\"] for node in nodes]\n",
        "        embeddings = embedder.encode(passages, convert_to_tensor=True).cpu().numpy()\n",
        "        print(f\"‚úÖ Total Chunks Created: {len(passages)}\")\n",
        "        return passages, doc_map, embeddings\n",
        "    else:\n",
        "        # fallback to fixed chunking\n",
        "        passages = []\n",
        "        doc_map = []\n",
        "        for name, text in docs.items():\n",
        "            for i in range(0, len(text), chunk_size):\n",
        "                chunk = text[i:i+chunk_size]\n",
        "                passages.append(chunk)\n",
        "                doc_map.append(name)\n",
        "        embeddings = embedder.encode(passages, convert_to_tensor=True).cpu().numpy()\n",
        "        return passages, doc_map, embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrEXAsnlN4Zv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def search(query, embedder, passages, embeddings):\n",
        "    query_vec = embedder.encode([query])[0]\n",
        "    query_vec = np.array(query_vec).astype('float32').reshape(1, -1)\n",
        "\n",
        "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "    index.add(embeddings)\n",
        "    D, I = index.search(query_vec, 1)\n",
        "    return passages[I[0][0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpvRxGpWN5bc"
      },
      "outputs": [],
      "source": [
        "def load_model(name, model_type):\n",
        "    if model_type == \"transformers\":\n",
        "        tokenizer = AutoTokenizer.from_pretrained(name)\n",
        "        model = AutoModelForCausalLM.from_pretrained(name, device_map=\"auto\", torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)\n",
        "        pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "        return lambda prompt: pipe(prompt, max_new_tokens=128, do_sample=True)[0]['generated_text']\n",
        "    elif model_type == \"llama-cpp\":\n",
        "        return Llama(model_path=name, n_ctx=2048, n_threads=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1hWwROXN9e_"
      },
      "outputs": [],
      "source": [
        "def generate_answer(model, query, context, model_type):\n",
        "    prompt = f\"Answer this question based on the context:\\nContext: {context}\\nQuestion: {query}\"\n",
        "    if model_type == \"llama-cpp\":\n",
        "        return model(prompt)[\"choices\"][0][\"text\"].strip()\n",
        "    else:\n",
        "        return model(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v23bSRfOBk8"
      },
      "outputs": [],
      "source": [
        "# STEP 4: Run RAG\n",
        "import pandas as pd\n",
        "results = []  # this will hold all results across experiments\n",
        "def run_rag(model_name, model_type, embedder_name=\"all-MiniLM-L6-v2\", chunk_size=300, chunk_overlap=30):\n",
        "    print(f\"\\nüîç Running RAG with model: {model_name}\")\n",
        "    embedder = SentenceTransformer(embedder_name)\n",
        "    documents = extract_text_from_pdfs()\n",
        "\n",
        "    passages, doc_map, embeddings = embed_documents(\n",
        "        documents,\n",
        "        embedder,\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "        use_semantic=True\n",
        "    )\n",
        "\n",
        "    model = load_model(model_name, model_type)\n",
        "\n",
        "    for doc, query in queries.items():\n",
        "        print(f\"\\nüìÑ Document: {doc}\")\n",
        "        print(f\"‚ùì Query: {query}\")\n",
        "        start = time.time()\n",
        "        relevant = search(query, embedder, passages, embeddings)\n",
        "        answer = generate_answer(model, query, relevant, model_type)\n",
        "        end = time.time()\n",
        "        print(f\"üìå Retrieved: {relevant[:80]}...\")\n",
        "        print(f\"üí¨ Answer: {answer.strip()}\")\n",
        "        print(f\"‚ö° Speed: {round(end - start, 2)}s\")\n",
        "\n",
        "        # Append result to global list\n",
        "        results.append({\n",
        "            \"Model\": model_name,\n",
        "            \"Chunk Size\": chunk_size,\n",
        "            \"Chunk Overlap\": chunk_overlap,\n",
        "            \"Document\": doc,\n",
        "            \"Query\": query,\n",
        "            \"Retrieved Context\": relevant[:80],\n",
        "            \"Answer\": answer.strip(),\n",
        "            \"Time (s)\": round(end - start, 2)\n",
        "        })\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear results\n",
        "results = []\n",
        "\n",
        "# Small chunks (100 tokens), no overlap\n",
        "run_rag(\"microsoft/phi-2\", \"transformers\", chunk_size=100, chunk_overlap=0)\n",
        "\n",
        "# Medium chunks (300 tokens), small overlap\n",
        "run_rag(\"microsoft/phi-2\", \"transformers\", chunk_size=300, chunk_overlap=30)\n",
        "\n",
        "# Large chunks (500 tokens), large overlap\n",
        "run_rag(\"microsoft/phi-2\", \"transformers\", chunk_size=500, chunk_overlap=100)\n"
      ],
      "metadata": {
        "id": "X6MMVrNDTalg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_rag(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", \"transformers\", chunk_size=100, chunk_overlap=0)\n",
        "run_rag(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", \"transformers\", chunk_size=300, chunk_overlap=30)\n",
        "run_rag(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", \"transformers\", chunk_size=500, chunk_overlap=100)"
      ],
      "metadata": {
        "id": "jxCh8dP9U-gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_rag(\"/content/mistral-7b-instruct-v0.2.Q4_K_M.gguf\", \"llama-cpp\", chunk_size=100, chunk_overlap=0)\n",
        "run_rag(\"/content/mistral-7b-instruct-v0.2.Q4_K_M.gguf\", \"llama-cpp\", chunk_size=300, chunk_overlap=30)\n",
        "run_rag(\"/content/mistral-7b-instruct-v0.2.Q4_K_M.gguf\", \"llama-cpp\", chunk_size=500, chunk_overlap=100)"
      ],
      "metadata": {
        "id": "jGK5c1kOV1co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUP6bwJPOCZX"
      },
      "outputs": [],
      "source": [
        "\"\"\" # All model setups\n",
        "model_configs = [\n",
        "    {\"name\": \"microsoft/phi-2\", \"type\": \"transformers\"},\n",
        "    {\"name\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", \"type\": \"transformers\"},\n",
        "    {\"name\": \"/content/mistral-7b-instruct-v0.2.Q4_K_M.gguf\", \"type\": \"llama-cpp\"},\n",
        "]\n",
        "\n",
        "# Chunk sizes and overlaps to test\n",
        "chunk_configs = [\n",
        "    {\"chunk_size\": 100, \"chunk_overlap\": 0},\n",
        "    {\"chunk_size\": 300, \"chunk_overlap\": 30},\n",
        "    {\"chunk_size\": 500, \"chunk_overlap\": 100},\n",
        "]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFI0UvJ-iVfV"
      },
      "outputs": [],
      "source": [
        "\"\"\" results = []\n",
        "\n",
        "for model_config in model_configs:\n",
        "    for chunk_config in chunk_configs:\n",
        "        run_rag(\n",
        "            model_name=model_config[\"name\"],\n",
        "            model_type=model_config[\"type\"],\n",
        "            chunk_size=chunk_config[\"chunk_size\"],\n",
        "            chunk_overlap=chunk_config[\"chunk_overlap\"]\n",
        "        )\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8233GtpXf74m"
      },
      "outputs": [],
      "source": [
        "df_results = pd.DataFrame(results)\n",
        "df_results"
      ]
    },
    {
      "source": [
        "from google.colab import sheets\n",
        "sheet = sheets.InteractiveSheet(df=df_results)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "id": "KXBNNZJTrOCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to CSV\n",
        "df_results.to_csv(\"rag_results.csv\", index=False)\n",
        "\n",
        "# Download to your local machine\n",
        "from google.colab import files\n",
        "files.download(\"rag_results.csv\")"
      ],
      "metadata": {
        "id": "6fNyGk1irpJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Gnc-iQVHaVAH"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOS2G78CWancbIEQJ7r12ds",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}